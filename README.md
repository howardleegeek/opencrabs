[![Rust Edition](https://img.shields.io/badge/rust-2024_edition-orange.svg)](https://www.rust-lang.org/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE.md)
[![CI](https://github.com/adolfousier/opencrabs/actions/workflows/ci.yml/badge.svg)](https://github.com/adolfousier/opencrabs/actions/workflows/ci.yml)
[![GitHub Stars](https://img.shields.io/github/stars/adolfousier/opencrabs?style=social)](https://github.com/adolfousier/opencrabs)

# OpenCrabs

**Rust-based open-claw inspired orchestration layer for software development.**

> A terminal-native AI orchestration agent written in Rust with Ratatui. Inspired by [Open Claw](https://github.com/openclaw/openclaw).

```
    ___                    ___           _
   / _ \ _ __  ___ _ _    / __|_ _ __ _| |__  ___
  | (_) | '_ \/ -_) ' \  | (__| '_/ _` | '_ \(_-<
   \___/| .__/\___|_||_|  \___|_| \__,_|_.__//__/
        |_|

 ğŸ¦€ Shell Yeah! AI Orchestration at Rust Speed.

```

**Author:** [Adolfo Usier](https://github.com/adolfousier)

---

## Table of Contents

- [Screenshots](#-screenshots)
- [Core Features](#-core-features)
- [Supported AI Providers](#-supported-ai-providers)
- [Quick Start](#-quick-start)
- [Onboarding Wizard](#-onboarding-wizard)
- [Authentication Methods](#-authentication-methods)
- [Using Local LLMs](#-using-local-llms)
- [Configuration](#-configuration)
- [Tool System](#-tool-system)
- [Plan Mode](#-plan-mode)
- [Keyboard Shortcuts](#-keyboard-shortcuts)
- [Debug and Logging](#-debug-and-logging)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Development](#-development)
- [Platform Notes](#-platform-notes)
- [Troubleshooting](#-troubleshooting)
- [Disclaimers](#-disclaimers)
- [Contributing](#-contributing)
- [License](#-license)
- [Acknowledgments](#-acknowledgments)

---

## ğŸ“¸ Screenshots

![Splash](src/screenshots/splash.png)

![Onboarding](src/screenshots/onboard1.png)

![Provider Auth](src/screenshots/onboard2.png)

![Workspace](src/screenshots/onboard3.png)

![Chat](src/screenshots/opencrabs-ui.png)

---

## ğŸ¯ Core Features

### AI & Providers
| Feature | Description |
|---------|-------------|
| **Multi-Provider** | Anthropic Claude (with OAuth), OpenAI, OpenRouter (400+ models), Qwen, Azure, and any OpenAI-compatible API. Model lists fetched live from provider APIs â€” new models available instantly |
| **Real-time Streaming** | Character-by-character response streaming with animated spinner showing model name and live text |
| **Local LLM Support** | Run with LM Studio, Ollama, or any OpenAI-compatible endpoint â€” 100% private, zero-cost |
| **Cost Tracking** | Per-message token count and cost displayed in header |
| **Context Awareness** | Live context usage indicator showing actual token counts (e.g. `ctx: 45K/200K (23%)`); auto-compaction at 70% with tool overhead budgeting; accurate tiktoken-based counting calibrated against API actuals |
| **3-Tier Memory** | (1) **Brain MEMORY.md** â€” user-curated durable memory loaded every turn, (2) **Daily Logs** â€” auto-compaction summaries at `~/.opencrabs/memory/YYYY-MM-DD.md`, (3) **Hybrid Memory Search** â€” FTS5 keyword search + local vector embeddings (embeddinggemma-300M, 768-dim) combined via Reciprocal Rank Fusion. Runs entirely local â€” no API key, no cost, works offline |
| **Dynamic Brain System** | System brain assembled from workspace MD files (SOUL, IDENTITY, USER, AGENTS, TOOLS, MEMORY) â€” all editable live between turns |

### Multimodal Input
| Feature | Description |
|---------|-------------|
| **Image Attachments** | Paste image paths or URLs into the input â€” auto-detected and attached as vision content blocks for multimodal models |
| **PDF Support** | Attach PDF files by path â€” native Anthropic PDF support; for other providers, text is extracted locally via `pdf-extract` |
| **Document Parsing** | Built-in `parse_document` tool extracts text from PDF, DOCX, HTML, TXT, MD, JSON, XML |
| **Voice (STT)** | Telegram voice notes transcribed via Groq Whisper (`whisper-large-v3-turbo`) and processed as text |
| **Voice (TTS)** | Agent replies to voice notes with audio via OpenAI TTS (`gpt-4o-mini-tts`, `ash` voice); falls back to text if disabled |
| **Attachment Indicator** | Attached images show as `[IMG1:filename.png]` in the input title bar |

### Messaging Integrations
| Feature | Description |
|---------|-------------|
| **Telegram Bot** | Full-featured Telegram bot running alongside the TUI â€” shared session, photo/voice support, allowlisted user IDs |
| **WhatsApp** | Connect via QR code pairing at runtime ("connect my WhatsApp") or from onboarding wizard. Text + image support, shared session with TUI, phone allowlist, session persists across restarts |
| **Slack** | Coming soon |

### Terminal UI
| Feature | Description |
|---------|-------------|
| **Cursor Navigation** | Full cursor movement: Left/Right arrows, Ctrl+Left/Right word jump, Home/End, Delete, Backspace at position |
| **Input History** | Persistent command history (`~/.opencrabs/history.txt`), loaded on startup, capped at 500 entries |
| **Inline Tool Approval** | Claude Code-style `â¯ Yes / Always / No` selector with arrow key navigation |
| **Inline Plan Approval** | Interactive plan review selector (Approve / Reject / Request Changes / View Plan) |
| **Session Management** | Create, rename, delete sessions with persistent SQLite storage; token counts and context % per session |
| **Scroll While Streaming** | Scroll up during streaming without being yanked back to bottom; auto-scroll re-enables when you scroll back down or send a message |
| **Compaction Summary** | Auto-compaction shows the full summary in chat as a system message â€” see exactly what the agent remembered |
| **Syntax Highlighting** | 100+ languages with line numbers via syntect |
| **Markdown Rendering** | Rich text formatting with code blocks, headings, lists, and inline styles |
| **Tool Context Persistence** | Tool call groups saved to DB and reconstructed on session reload â€” no vanishing tool history |
| **Multi-line Input** | Alt+Enter / Shift+Enter for newlines; Enter to send |
| **Abort Processing** | EscapeÃ—2 within 3 seconds to cancel any in-progress request |

### Agent Capabilities
| Feature | Description |
|---------|-------------|
| **Built-in Tools** | Read/write/edit files, bash, glob, grep, web search (EXA, Brave), plan mode, and more |
| **Plan Mode** | Structured task decomposition with dependency graphs, complexity ratings, and inline approval workflow |
| **Self-Sustaining** | Agent can modify its own source, build, test, and hot-restart via Unix `exec()` |
| **Natural Language Commands** | Tell OpenCrabs to create slash commands â€” it writes them to `commands.toml` autonomously via the `config_manager` tool |
| **Live Settings** | Agent can read/write `config.toml` at runtime; Settings TUI screen (press `S`) shows current config; approval policy persists across restarts |
| **Web Search** | EXA AI (neural, free via MCP) and Brave Search APIs |
| **Debug Logging** | `--debug` flag enables file logging; `DEBUG_LOGS_LOCATION` env var for custom log directory |

---

## ğŸŒ Supported AI Providers

### Anthropic Claude

**Models:** `claude-opus-4-6`, `claude-sonnet-4-5-20250929`, `claude-haiku-4-5-20251001`, plus legacy Claude 3.x models

**Authentication:**

| Method | Env Variable | Header |
|--------|-------------|--------|
| **OAuth / Claude Max** (recommended) | `ANTHROPIC_MAX_SETUP_TOKEN` | `Authorization: Bearer` + `anthropic-beta: oauth-2025-04-20` |
| Standard API Key | `ANTHROPIC_API_KEY` | `x-api-key` |

OAuth tokens are auto-detected by the `sk-ant-oat` prefix. When `ANTHROPIC_MAX_SETUP_TOKEN` is set, it takes priority over `ANTHROPIC_API_KEY`.

Set a custom model with `ANTHROPIC_MAX_MODEL` (e.g., `claude-opus-4-6`).

**Features:** Streaming, tools, cost tracking, automatic retry with backoff

### OpenAI

**Models:** GPT-4 Turbo, GPT-4, GPT-3.5 Turbo

**Setup:** `export OPENAI_API_KEY="sk-YOUR_KEY"`

Compatible with any OpenAI-compatible API endpoint via `OPENAI_BASE_URL`.

### OpenRouter â€” 400+ Models, One Key

**Setup:** `export OPENROUTER_API_KEY="sk-or-YOUR_KEY"` â€” get one at [openrouter.ai/keys](https://openrouter.ai/keys)

Access 400+ models from every major provider through a single API key â€” Anthropic, OpenAI, Google, Meta, Mistral, DeepSeek, Qwen, and many more. Includes **free models** (DeepSeek-R1, Llama 3.3, Gemma 2, Mistral 7B) and stealth/preview models as they drop.

Model list is **fetched live** from the OpenRouter API during onboarding and via `/models` â€” no binary update needed when new models are added.

### Qwen (via OpenAI-compatible)

**Setup:** Configure via `QWEN_API_KEY` and `QWEN_BASE_URL`.

### OpenAI-Compatible Local / Cloud APIs

| Provider | Status | Setup |
|----------|--------|-------|
| **LM Studio** | Tested | `OPENAI_BASE_URL="http://localhost:1234/v1"` |
| **Ollama** | Compatible | `OPENAI_BASE_URL="http://localhost:11434/v1"` |
| **LocalAI** | Compatible | `OPENAI_BASE_URL="http://localhost:8080/v1"` |
| Groq | Compatible | `OPENAI_BASE_URL="https://api.groq.com/openai/v1"` |

**Provider priority:** Qwen > Anthropic > OpenAI (fallback). The first provider with a configured API key is used. `OPENAI_API_KEY` is isolated to TTS only â€” it won't create a text provider unless explicitly configured.

---

## ğŸš€ Quick Start

### Option 1: Download Binary (just run it)

Grab a pre-built binary from [GitHub Releases](https://github.com/adolfousier/opencrabs/releases) â€” available for Linux (amd64/arm64), macOS (amd64/arm64), and Windows.

```bash
# Download, extract, run
tar xzf opencrabs-linux-amd64.tar.gz
./opencrabs
```

The onboarding wizard handles everything on first run. Set your API key via environment variable or the wizard will prompt you.

> **Note:** `/rebuild` works even with pre-built binaries â€” it auto-clones the source to `~/.opencrabs/source/` on first use, then builds and hot-restarts. For active development or adding custom tools, Option 2 gives you the source tree directly.

### Option 2: Build from Source (full control)

Required for `/rebuild`, adding custom tools, or modifying the agent.

**Prerequisites:**
- **Rust nightly (2024 edition)** â€” [Install Rust](https://rustup.rs/), then `rustup toolchain install nightly`. The project includes a `rust-toolchain.toml` that selects nightly automatically
- **An API key** from at least one supported provider
- **SQLite** (bundled via sqlx)
- **Linux:** `build-essential`, `pkg-config`, `libssl-dev`, `libchafa-dev`

```bash
# Clone
git clone https://github.com/adolfousier/opencrabs.git
cd opencrabs

# Set up credentials
cp .env.example .env
# Edit .env with your API key(s)

# Build & run (development)
cargo run --bin opencrabs

# Or build release and run directly
cargo build --release
./target/release/opencrabs
```

OpenCrabs auto-loads `.env` via `dotenvy` at startup â€” no need to manually export variables.

> **First run?** The onboarding wizard will guide you through provider setup, workspace, and more. See [Onboarding Wizard](#-onboarding-wizard).

### Option 3: Docker (sandboxed)

Run OpenCrabs in an isolated container. Build takes ~15min (Rust release + LTO).

```bash
# Clone and run
git clone https://github.com/adolfousier/opencrabs.git
cd opencrabs

# Option A: With .env file (auto-loaded)
cp .env.example .env   # add your API keys
docker compose -f src/docker/compose.yml up --build

# Option B: No .env â€” onboarding wizard handles setup interactively
docker compose -f src/docker/compose.yml run opencrabs
```

Config, workspace, and memory DB persist in a Docker volume across restarts. Keys are passed via environment â€” never baked into the image.

### CLI Commands

```bash
# Interactive TUI (default)
cargo run --bin opencrabs
cargo run --bin opencrabs -- chat

# Onboarding wizard (first-time setup)
cargo run --bin opencrabs -- onboard
cargo run --bin opencrabs -- chat --onboard   # Force wizard before chat

# Non-interactive single command
cargo run --bin opencrabs -- run "What is Rust?"
cargo run --bin opencrabs -- run --format json "List 3 programming languages"
cargo run --bin opencrabs -- run --format markdown "Explain async/await"

# Configuration
cargo run --bin opencrabs -- init              # Initialize config
cargo run --bin opencrabs -- config            # Show current config
cargo run --bin opencrabs -- config --show-secrets

# Database
cargo run --bin opencrabs -- db init           # Initialize database
cargo run --bin opencrabs -- db stats          # Show statistics

# Keyring (secure OS credential storage)
cargo run --bin opencrabs -- keyring set anthropic YOUR_KEY
cargo run --bin opencrabs -- keyring get anthropic
cargo run --bin opencrabs -- keyring list

# Debug mode
cargo run --bin opencrabs -- -d                # Enable file logging
cargo run --bin opencrabs -- -d run "analyze this"

# Log management
cargo run --bin opencrabs -- logs status
cargo run --bin opencrabs -- logs view
cargo run --bin opencrabs -- logs view -l 100
cargo run --bin opencrabs -- logs clean
cargo run --bin opencrabs -- logs clean -d 3
```

> **Tip:** After `cargo build --release`, run the binary directly: `./target/release/opencrabs`

**Output formats** for non-interactive mode: `text` (default), `json`, `markdown`

---

## ğŸ§™ Onboarding Wizard

First-time users are guided through an 8-step setup wizard that appears automatically after the splash screen.

### How It Triggers

- **Automatic:** When no `~/.config/opencrabs/config.toml` exists and no API keys are set in env/keyring
- **CLI:** `cargo run --bin opencrabs -- onboard` (or `opencrabs onboard` after install)
- **Chat flag:** `cargo run --bin opencrabs -- chat --onboard` to force the wizard before chat
- **Slash command:** Type `/onboard` in the chat to re-run it anytime

### The 8 Steps

| Step | Title | What It Does |
|------|-------|-------------|
| 1 | **Mode Selection** | QuickStart (sensible defaults) vs Advanced (full control) |
| 2 | **Model & Auth** | Pick provider (Anthropic, OpenAI, Gemini, Qwen, OpenRouter, Custom) â†’ enter token/key â†’ model list fetched live from API â†’ select model. Auto-detects existing keys from env/keyring |
| 3 | **Workspace** | Set brain workspace path (default `~/.opencrabs/`) â†’ seed template files (SOUL.md, IDENTITY.md, etc.) |
| 4 | **Gateway** | Configure HTTP API gateway: port, bind address, auth mode |
| 5 | **Channels** | Toggle messaging integrations (Telegram, Discord, WhatsApp, Signal, Google Chat, iMessage) |
| 6 | **Daemon** | Install background service (systemd on Linux, LaunchAgent on macOS) |
| 7 | **Health Check** | Verify API key, config, workspace â€” shows pass/fail summary |
| 8 | **Brain Personalization** | Tell the agent about yourself and your preferred agent vibe â†’ AI generates personalized brain files (SOUL.md, IDENTITY.md, USER.md, etc.) |

**QuickStart mode** skips steps 4-6 with sensible defaults. **Advanced mode** lets you configure everything.

### Wizard Navigation

| Key | Action |
|-----|--------|
| `Tab` / `Shift+Tab` | Navigate between fields |
| `Up` / `Down` | Scroll through lists |
| `Enter` | Confirm / next step |
| `Space` | Toggle checkboxes |
| `Esc` | Go back one step |

---

## ğŸ”‘ Authentication Methods

### Option A: OAuth / Claude Max (Recommended for Claude)

```bash
# In .env file:
ANTHROPIC_MAX_SETUP_TOKEN=sk-ant-oat01-YOUR_OAUTH_TOKEN
ANTHROPIC_MAX_MODEL=claude-opus-4-6
```

The `sk-ant-oat` prefix is auto-detected. OpenCrabs will use `Authorization: Bearer` with the `anthropic-beta: oauth-2025-04-20` header.

### Option B: Standard API Key

```bash
# In .env or exported:
ANTHROPIC_API_KEY=sk-ant-api03-YOUR_KEY
OPENAI_API_KEY=sk-YOUR_KEY
```

### Option C: OS Keyring (Secure Storage)

```bash
cargo run -- keyring set anthropic YOUR_API_KEY
# Encrypted by OS (Windows Credential Manager / macOS Keychain / Linux Secret Service)
# Automatically loaded on startup, no plaintext files
```

**Priority:** Keyring > `ANTHROPIC_MAX_SETUP_TOKEN` > `ANTHROPIC_API_KEY` > config file

---

## ğŸ  Using Local LLMs

OpenCrabs works with any OpenAI-compatible local inference server for **100% private, zero-cost** operation.

### LM Studio (Recommended)

1. Download and install [LM Studio](https://lmstudio.ai/)
2. Download a model (e.g., `qwen2.5-coder-7b-instruct`, `Mistral-7B-Instruct`, `Llama-3-8B`)
3. Start the local server (default port 1234)
4. Configure OpenCrabs:

```bash
# .env or environment
OPENAI_API_KEY="lm-studio"
OPENAI_BASE_URL="http://localhost:1234/v1"
```

Or via `opencrabs.toml`:

```toml
[providers.openai]
enabled = true
base_url = "http://localhost:1234/v1/chat/completions"
default_model = "qwen2.5-coder-7b-instruct"   # Must EXACTLY match LM Studio model name
```

> **Critical:** The `default_model` value must exactly match the model name shown in LM Studio's Local Server tab (case-sensitive).

### Ollama

```bash
ollama pull mistral
# Configure:
OPENAI_BASE_URL="http://localhost:11434/v1"
OPENAI_API_KEY="ollama"
```

### Recommended Models

| Model | RAM | Best For |
|-------|-----|----------|
| Qwen-2.5-7B-Instruct | 16 GB | Coding tasks |
| Mistral-7B-Instruct | 16 GB | General purpose, fast |
| Llama-3-8B-Instruct | 16 GB | Balanced performance |
| DeepSeek-Coder-6.7B | 16 GB | Code-focused |
| TinyLlama-1.1B | 4 GB | Quick responses, lightweight |

**Tips:**
- Start with Q4_K_M quantization for best speed/quality balance
- Set context length to 8192+ in LM Studio settings
- Use `Ctrl+N` to start a new session if you hit context limits
- GPU acceleration significantly improves inference speed

### Cloud vs Local Comparison

| Aspect | Cloud (Anthropic) | Local (LM Studio) |
|--------|-------------------|-------------------|
| Privacy | Data sent to API | 100% private |
| Cost | Per-token pricing | Free after download |
| Speed | 1-2s (network) | 2-10s (hardware-dependent) |
| Quality | Excellent (Claude 4.x) | Good (model-dependent) |
| Offline | Requires internet | Works offline |

See [LM_STUDIO_GUIDE.md](src/docs/guides/LM_STUDIO_GUIDE.md) for detailed setup and troubleshooting.

---

## ğŸ“ Configuration

### Configuration File (`config.toml`)

OpenCrabs searches for config in this order:
1. `~/.opencrabs/config.toml` (primary)
2. `~/.config/opencrabs/config.toml` (legacy fallback)
3. `./opencrabs.toml` (current directory override)

Environment variables override config file settings. `.env` files are auto-loaded.

```bash
# Initialize config
cargo run -- init

# Copy the example
cp config.toml.example ~/.config/opencrabs/opencrabs.toml
```

### Example: Hybrid Setup (Local + Cloud)

```toml
[database]
path = "~/.opencrabs/opencrabs.db"

# Local LLM for daily development
[providers.openai]
enabled = true
base_url = "http://localhost:1234/v1/chat/completions"
default_model = "qwen2.5-coder-7b-instruct"

# Cloud API for complex tasks
[providers.anthropic]
enabled = true
default_model = "claude-opus-4-6"
# API key via env var or keyring
```

### Environment Variables

| Variable | Provider | Description |
|----------|----------|-------------|
| `ANTHROPIC_MAX_SETUP_TOKEN` | Anthropic (OAuth) | OAuth Bearer token (takes priority) |
| `ANTHROPIC_MAX_MODEL` | Anthropic | Custom default model |
| `ANTHROPIC_API_KEY` | Anthropic | Standard API key |
| `OPENAI_API_KEY` | OpenAI / Compatible | API key |
| `OPENAI_BASE_URL` | OpenAI / Compatible | Custom endpoint URL |
| `OPENROUTER_API_KEY` | OpenRouter | API key â€” 400+ models, one key ([openrouter.ai/keys](https://openrouter.ai/keys)) |
| `QWEN_API_KEY` | Qwen | API key |
| `QWEN_BASE_URL` | Qwen | Custom endpoint URL |
| `EXA_API_KEY` | EXA AI Search | Neural web search â€” free via MCP by default; set key for direct API with higher rate limits |
| `BRAVE_API_KEY` | Brave Search | Web search (free $5/mo credits at brave.com/search/api) |
| `GROQ_API_KEY` | Groq (STT) | Voice transcription via Whisper (`whisper-large-v3-turbo`) |
| `DEBUG_LOGS_LOCATION` | Logging | Custom log directory path (default: `.opencrabs/logs/`) |
| `TELEGRAM_BOT_TOKEN` | Telegram | Bot token from @BotFather |
| `TELEGRAM_ALLOWED_USERS` | Telegram | Comma-separated allowlisted Telegram user IDs |

---

## ğŸ”§ Tool System

OpenCrabs includes a built-in tool execution system. The AI can use these tools during conversation:

| Tool | Description |
|------|-------------|
| `read_file` | Read file contents with syntax awareness |
| `write_file` | Create or modify files |
| `edit_file` | Precise text replacements in files |
| `bash` | Execute shell commands |
| `ls` | List directory contents |
| `glob` | Find files matching patterns |
| `grep` | Search file contents with regex |
| `web_search` | Search the web (DuckDuckGo, always available, no key needed) |
| `exa_search` | Neural web search via EXA AI (free via MCP, no API key needed) |
| `brave_search` | Web search via Brave Search (set `BRAVE_API_KEY` â€” free $5/mo credits) |
| `execute_code` | Run code in various languages |
| `notebook_edit` | Edit Jupyter notebooks |
| `parse_document` | Extract text from PDF, DOCX, HTML |
| `task_manager` | Manage agent tasks |
| `http_request` | Make HTTP requests |
| `memory_search` | Hybrid semantic search across past memory logs â€” FTS5 keyword + vector embeddings (768-dim, local GGUF model) combined via RRF. No API key needed, runs offline |
| `config_manager` | Read/write config.toml and commands.toml at runtime (change settings, add/remove commands, reload config) |
| `session_context` | Access session information |
| `plan` | Create structured execution plans |

---

## ğŸ“‹ Plan Mode

Plan Mode breaks complex tasks into structured, reviewable, executable plans.

### Workflow

1. **Request:** Ask the AI to create a plan using the plan tool
2. **AI creates:** Structured tasks with dependencies, complexity estimates, and types
3. **Review:** Press `Ctrl+P` to view the plan in a visual TUI panel
4. **Decide:** An inline selector appears with arrow key navigation:
   - **Approve** â€” Execute the plan
   - **Reject** â€” Discard the plan
   - **Request Changes** â€” Returns to chat with context for revisions
   - **View Plan** â€” Open the full plan panel (`Ctrl+P`)

### Plan States

Plans progress through: **Draft** â†’ **PendingApproval** â†’ **Approved** â†’ **InProgress** â†’ **Completed**

Tasks have 10 types: Research, Edit, Create, Delete, Test, Refactor, Documentation, Configuration, Build, Other

Each task tracks: status (Pending/InProgress/Completed/Skipped/Failed/Blocked), dependencies, complexity (1-5), and timestamps.

### Example

```
You: Use the plan tool to create a plan for implementing JWT authentication.
     Add tasks for: adding dependencies, token generation, validation
     middleware, updating login endpoint, and writing tests.
     Call operation=finalize when done.

OpenCrabs: [Creates plan with 5 tasks, dependencies, complexity ratings]
         âœ“ Plan finalized! Press Ctrl+P to review.
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“‹ Plan: JWT Authentication                                 â”‚
â”‚ Status: Pending Approval â€¢ Tasks: 5 â€¢ Complexity: Medium    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. [â¹] Add jsonwebtoken dependency (â­â­)                   â”‚
â”‚ 2. [â¹] Implement token generation (â­â­â­â­) â†’ depends on #1 â”‚
â”‚ 3. [â¹] Build validation middleware (â­â­â­â­â­) â†’ depends on #2â”‚
â”‚ 4. [â¹] Update login endpoint (â­â­â­) â†’ depends on #2       â”‚
â”‚ 5. [â¹] Write integration tests (â­â­â­) â†’ depends on #3, #4 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Ctrl+A] Approve  [Ctrl+R] Reject  [Ctrl+I] Changes  [Esc]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tip for local LLMs:** Be explicit about tool usage â€” say "use the plan tool with operation=create" rather than "create a plan".

See [Plan Mode User Guide](src/docs/PLAN_MODE_USER_GUIDE.md) for full documentation.

---

## âŒ¨ï¸ Keyboard Shortcuts

### Global

| Shortcut | Action |
|----------|--------|
| `Ctrl+C` | First press clears input, second press (within 3s) quits |
| `Ctrl+N` | New session |
| `Ctrl+L` | List/switch sessions |
| `Ctrl+K` | Clear current session |
| `Page Up/Down` | Scroll chat history |
| `Mouse Scroll` | Scroll chat history |
| `Escape` | Clear input / close overlay |

### Chat Mode

| Shortcut | Action |
|----------|--------|
| `Enter` | Send message |
| `Alt+Enter` / `Shift+Enter` | New line in input |
| `â†` / `â†’` | Move cursor one character |
| `Ctrl+â†` / `Ctrl+â†’` | Jump by word |
| `Home` / `End` | Jump to start/end of input |
| `Delete` | Delete character after cursor |
| `Ctrl+Backspace` / `Alt+Backspace` | Delete word before cursor |
| `Escape` Ã—2 | Abort in-progress request |
| `/help` | Open help dialog |
| `/model` | Show current model |
| `/models` | Switch model (fetches live from provider API) |
| `/usage` | Token/cost stats |
| `/onboard` | Run setup wizard |
| `/sessions` | Open session manager |
| `/approve` | Tool approval policy selector (approve-only / session / yolo) |
| `/compact` | Compact context (summarize + trim for long sessions) |
| `/rebuild` | Build from source & hot-restart â€” auto-clones repo if no source tree found |
| `/settings` or `S` | Open Settings screen (provider, approval, commands, paths) |

### Sessions Mode

| Shortcut | Action |
|----------|--------|
| `â†‘` / `â†“` | Navigate sessions |
| `Enter` | Load selected session |
| `R` | Rename session |
| `D` | Delete session |
| `Esc` | Back to chat |

### Tool Approval (Inline)

When the AI requests a tool that needs permission, an inline approval prompt appears in chat:

| Shortcut | Action |
|----------|--------|
| `â†‘` / `â†“` | Navigate approval options |
| `Enter` | Confirm selected option |
| `D` / `Esc` | Deny the tool request |
| `V` | Toggle parameter details |

**Approval options:**

| Option | Effect |
|--------|--------|
| **Allow once** | Approve this single tool call |
| **Allow all for this task** | Auto-approve all tools this session (resets on session switch) |
| **Allow all moving forward** | Auto-approve all tools permanently (app lifetime) |

Use `/approve` to change your approval policy at any time (persisted to `config.toml`):

| Policy | Description |
|--------|-------------|
| **Approve-only** | Always ask before executing tools (default) |
| **Allow all (session)** | Auto-approve all tools for the current session |
| **Yolo mode** | Execute everything without approval until reset |

### Plan Approval (Inline)

When a plan is submitted for approval, an inline selector appears in chat:

| Shortcut | Action |
|----------|--------|
| `â†‘` / `â†“` | Navigate approval options (Approve / Reject / Request Changes / View Plan) |
| `Enter` | Confirm selected option |
| `Ctrl+P` | View full plan panel |

---

## ğŸ” Debug and Logging

OpenCrabs uses a **conditional logging system** â€” no log files by default.

```bash
# Enable debug mode (creates log files)
opencrabs -d
cargo run -- -d

# Logs stored in .opencrabs/logs/ (auto-gitignored)
# Daily rolling rotation, auto-cleanup after 7 days

# Management
opencrabs logs status    # Check logging status
opencrabs logs view      # View recent entries
opencrabs logs clean     # Clean old logs
opencrabs logs clean -d 3  # Clean logs older than 3 days
```

**When debug mode is enabled:**
- Log files created in `.opencrabs/logs/`
- DEBUG level with thread IDs, file names, line numbers
- Daily rolling rotation

**When disabled (default):**
- No log files created
- Only warnings and errors to stderr
- Clean workspace

---

## ğŸ§  Brain System & 3-Tier Memory

OpenCrabs's brain is **dynamic and self-sustaining**. Instead of a hardcoded system prompt, the agent assembles its personality, knowledge, and behavior from workspace files that can be edited between turns.

### Brain Workspace

The brain reads markdown files from `~/.opencrabs/` (or `OPENCRABS_BRAIN_PATH` env var):

```
~/.opencrabs/                  # Home â€” everything lives here
â”œâ”€â”€ SOUL.md                    # Personality, tone, hard behavioral rules
â”œâ”€â”€ IDENTITY.md                # Agent name, vibe, style, workspace path
â”œâ”€â”€ USER.md                    # Who the human is, how to work with them
â”œâ”€â”€ AGENTS.md                  # Workspace rules, memory system, safety policies
â”œâ”€â”€ TOOLS.md                   # Environment-specific notes (SSH hosts, API accounts)
â”œâ”€â”€ MEMORY.md                  # Long-term curated context (never touched by auto-compaction)
â”œâ”€â”€ SECURITY.md                # Security policies and access controls
â”œâ”€â”€ BOOT.md                    # Startup checklist (optional, runs on launch)
â”œâ”€â”€ HEARTBEAT.md               # Periodic task definitions (optional)
â”œâ”€â”€ BOOTSTRAP.md               # First-run onboarding wizard (deleted after setup)
â”œâ”€â”€ config.toml                # App configuration (provider, model, approval policy)
â”œâ”€â”€ commands.toml              # User-defined slash commands
â”œâ”€â”€ opencrabs.db               # SQLite â€” sessions, messages, plans
â””â”€â”€ memory/                    # Daily memory logs (auto-compaction summaries)
    â””â”€â”€ YYYY-MM-DD.md          # One per day, multiple compactions stack
```

Brain files are re-read **every turn** â€” edit them between messages and the agent immediately reflects the changes. Missing files are silently skipped; a hardcoded brain preamble is always present.

### 3-Tier Memory Architecture

| Tier | Location | Purpose | Managed By |
|------|----------|---------|------------|
| **1. Brain MEMORY.md** | `~/.opencrabs/MEMORY.md` | Durable, curated knowledge loaded into system brain every turn | You (the user) |
| **2. Daily Memory Logs** | `~/.opencrabs/memory/YYYY-MM-DD.md` | Auto-compaction summaries with structured breakdowns of each session | Auto (on compaction) |
| **3. Hybrid Memory Search** | `memory_search` tool (FTS5 + vector) | Hybrid semantic search â€” BM25 keyword + vector embeddings (768-dim, local GGUF) combined via Reciprocal Rank Fusion. No API key, zero cost, runs offline | Agent (via tool call) |

**How it works:**
1. When context hits 70%, auto-compaction summarizes the conversation into a structured breakdown (current task, decisions, files modified, errors, next steps)
2. The summary is saved to a daily log at `~/.opencrabs/memory/2026-02-15.md` (multiple compactions per day stack in the same file)
3. The summary is shown to you in chat so you see exactly what was remembered
4. The file is indexed in the background into the FTS5 database so the agent can search past logs with `memory_search`
5. Brain `MEMORY.md` is **never touched** by auto-compaction â€” it stays as your curated, always-loaded context

#### Hybrid Memory Search (FTS5 + Vector Embeddings)

Memory search combines two strategies via **Reciprocal Rank Fusion (RRF)** for best-of-both-worlds recall:

1. **FTS5 keyword search** â€” BM25-ranked full-text matching with porter stemming
2. **Vector semantic search** â€” 768-dimensional embeddings via a local GGUF model (embeddinggemma-300M, ~300 MB)

The embedding model downloads automatically on first TUI launch (~300 MB, one-time) and runs entirely on CPU. **No API key, no cloud service, no per-query cost, works offline.** If the model isn't available yet (first launch, still downloading), search gracefully falls back to FTS-only.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ~/.opencrabs/memory/               â”‚
â”‚  â”œâ”€â”€ 2026-02-15.md                  â”‚  Markdown files (daily logs)
â”‚  â”œâ”€â”€ 2026-02-16.md                  â”‚
â”‚  â””â”€â”€ 2026-02-17.md                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ index on startup +
               â”‚ after each compaction
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  memory.db  (SQLite WAL mode)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ documents + FTS5      â”‚ â”‚ vector embeddingsâ”‚ â”‚
â”‚  â”‚ (BM25, porter stem)   â”‚ â”‚ (768-dim, cosine)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ MATCH query          â”‚ cosine similarity
               â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Reciprocal Rank Fusion (k=60)                  â”‚
â”‚  Merges keyword + semantic results              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hybrid-ranked results with snippets            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why local embeddings instead of OpenAI/cloud?**

| | Local (embeddinggemma-300M) | Cloud API (e.g. OpenAI) |
|---|---|---|
| **Cost** | Free forever | ~$0.0001/query, adds up |
| **Privacy** | 100% local, nothing leaves your machine | Data sent to third party |
| **Latency** | ~2ms (in-process, no network) | 100-500ms (HTTP round-trip) |
| **Offline** | Works without internet | Requires internet |
| **Setup** | Automatic, no API key needed | Requires API key + billing |
| **Quality** | Excellent for code/session recall (768-dim) | Slightly better for general-purpose |
| **Size** | ~300 MB one-time download | N/A |

### User-Defined Slash Commands

Tell OpenCrabs in natural language: *"Create a /deploy command that runs deploy.sh"* â€” and it writes the command to `~/.opencrabs/commands.toml` via the `config_manager` tool:

```toml
[[commands]]
name = "/deploy"
description = "Deploy to staging server"
action = "prompt"
prompt = "Run the deployment script at ./scripts/deploy.sh for the staging environment."
```

Commands appear in autocomplete alongside built-in commands. After each agent response, `commands.toml` is automatically reloaded â€” no restart needed. Legacy `commands.json` files are auto-migrated on first load.

### Self-Sustaining Architecture

OpenCrabs can modify its own source code, build, test, and hot-restart itself â€” triggered by the agent via the `rebuild` tool or by the user via `/rebuild`:

```
/rebuild          # User-triggered: build â†’ restart prompt
rebuild tool      # Agent-triggered: build â†’ ProgressEvent::RestartReady â†’ restart prompt
```

**How it works:**

1. The agent edits source files using its built-in tools (read, write, edit, bash)
2. `SelfUpdater::build()` runs `cargo build --release` asynchronously
3. On success, a `ProgressEvent::RestartReady` is emitted â†’ bridged to `TuiEvent::RestartReady`
4. The TUI switches to **RestartPending** mode â€” user presses Enter to confirm
5. `SelfUpdater::restart(session_id)` replaces the process via Unix `exec()`
6. The new binary starts with `opencrabs chat --session <uuid>` â€” resuming the same conversation
7. A hidden wake-up message is sent to the agent so it greets the user and continues where it left off

**Two trigger paths:**

| Path | Entry point | Signal |
|------|-------------|--------|
| **Agent-triggered** | `rebuild` tool (called by the agent after editing source) | `ProgressCallback` â†’ `RestartReady` |
| **User-triggered** | `/rebuild` slash command | `TuiEvent::RestartReady` directly |

**Key details:**

- The running binary is in memory â€” source changes on disk don't affect it until restart
- If the build fails, the agent stays running and can read compiler errors to fix them
- Session persistence via SQLite means no conversation context is lost across restarts
- After restart, the agent auto-wakes with session context â€” no user input needed
- Brain files (`SOUL.md`, `MEMORY.md`, etc.) are re-read every turn, so edits take effect immediately without rebuild
- User-defined slash commands (`commands.toml`) also auto-reload after each agent response
- Hot restart is Unix-only (`exec()` syscall); on Windows the build/test steps work but restart requires manual relaunch

**Modules:**
- `src/brain/self_update.rs` â€” `SelfUpdater` struct with `auto_detect()`, `build()`, `test()`, `restart()`
- `src/llm/tools/rebuild.rs` â€” `RebuildTool` (agent-callable, emits `ProgressEvent::RestartReady`)

---

## ğŸ—ï¸ Architecture

```
Presentation Layer
    â†“
CLI (Clap) + TUI (Ratatui + Crossterm)
    â†“
Brain Layer (Dynamic system brain, user commands, config management, self-update)
    â†“
Application Layer
    â†“
Service Layer (Session, Message, Agent, Plan)
    â†“
Data Access Layer (SQLx + SQLite)
    â†“
Integration Layer (LLM Providers, LSP)
```

**Key Technologies:**

| Component | Crate |
|-----------|-------|
| Async Runtime | Tokio |
| Terminal UI | Ratatui + Crossterm |
| CLI Parsing | Clap (derive) |
| Database | SQLx (SQLite) |
| Serialization | Serde + TOML |
| HTTP Client | Reqwest |
| Syntax Highlighting | Syntect |
| Markdown | pulldown-cmark |
| LSP Client | Tower-LSP |
| Provider Registry | Crabrace |
| Memory Search | qmd (FTS5 + vector embeddings) |
| Error Handling | anyhow + thiserror + color-eyre |
| Logging | tracing + tracing-subscriber |
| Security | zeroize + keyring |

---

## ğŸ“ Project Structure

```
opencrabs/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs           # Entry point
â”‚   â”œâ”€â”€ lib.rs            # Library root (crate root â€” required by Rust)
â”‚   â”œâ”€â”€ error/            # Error types (OpenCrabsError, ErrorCode)
â”‚   â”œâ”€â”€ logging/          # Conditional logging system
â”‚   â”œâ”€â”€ app/              # Application lifecycle
â”‚   â”œâ”€â”€ brain/            # Dynamic brain system (v0.1.1)
â”‚   â”‚   â”œâ”€â”€ mod.rs        # Module root
â”‚   â”‚   â”œâ”€â”€ prompt_builder.rs  # BrainLoader â€” assembles system brain from workspace files
â”‚   â”‚   â”œâ”€â”€ commands.rs   # CommandLoader â€” user-defined slash commands (TOML, with JSON migration)
â”‚   â”‚   â””â”€â”€ self_update.rs # SelfUpdater â€” build, test, hot-restart via exec()
â”‚   â”œâ”€â”€ cli/              # Command-line interface (Clap)
â”‚   â”œâ”€â”€ config/           # Configuration (TOML + env + keyring)
â”‚   â”‚   â””â”€â”€ crabrace.rs   # Provider registry integration
â”‚   â”œâ”€â”€ db/               # Database layer (SQLx + SQLite)
â”‚   â”œâ”€â”€ services/         # Business logic (Session, Message, File, Plan)
â”‚   â”œâ”€â”€ memory/           # Memory search (built-in FTS5); data stored at ~/.opencrabs/memory/
â”‚   â”œâ”€â”€ llm/              # LLM integration
â”‚   â”‚   â”œâ”€â”€ agent/        # Agent service + context management
â”‚   â”‚   â”œâ”€â”€ provider/     # Provider implementations (Anthropic, OpenAI, Qwen)
â”‚   â”‚   â”œâ”€â”€ tools/        # Tool system (read, write, bash, glob, grep, memory_search, config_manager, etc.)
â”‚   â”‚   â””â”€â”€ prompt/       # Prompt engineering
â”‚   â”œâ”€â”€ tui/              # Terminal UI (Ratatui)
â”‚   â”‚   â”œâ”€â”€ onboarding.rs     # 7-step onboarding wizard (state + logic)
â”‚   â”‚   â”œâ”€â”€ onboarding_render.rs  # Wizard rendering
â”‚   â”‚   â”œâ”€â”€ splash.rs     # Splash screen
â”‚   â”‚   â”œâ”€â”€ app.rs        # App state + event handling
â”‚   â”‚   â”œâ”€â”€ render.rs     # Main render dispatch
â”‚   â”‚   â””â”€â”€ runner.rs     # TUI event loop
â”‚   â”œâ”€â”€ lsp/              # LSP integration
â”‚   â”œâ”€â”€ events/           # Event handling
â”‚   â”œâ”€â”€ message/          # Message types
â”‚   â”œâ”€â”€ sync/             # Synchronization utilities
â”‚   â”œâ”€â”€ macros/           # Rust macros
â”‚   â”œâ”€â”€ utils/            # Utilities (retry, etc.)
â”‚   â”œâ”€â”€ migrations/       # SQLite migrations
â”‚   â”œâ”€â”€ tests/            # Integration tests
â”‚   â”œâ”€â”€ benches/          # Criterion benchmarks
â”‚   â””â”€â”€ docs/             # Documentation + screenshots
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ config.toml.example
â”œâ”€â”€ .env.example
â””â”€â”€ LICENSE.md
```

---

## ğŸ› ï¸ Development

### Build from Source

```bash
# Development build
cargo build

# Release build (optimized, LTO, stripped)
cargo build --release

# Small release build
cargo build --profile release-small

# Run tests
cargo test

# Run benchmarks
cargo bench

# Format + lint
cargo fmt
cargo clippy -- -D warnings
```

### Feature Flags

| Feature | Description |
|---------|-------------|
| `openai` | Enable async-openai integration |
| `aws-bedrock` | Enable AWS Bedrock runtime |
| `all-llm` | Enable all LLM provider features |
| `profiling` | Enable pprof flamegraph profiling (Unix only) |

### Performance

| Metric | Value |
|--------|-------|
| Binary size | 34 MB (release, stripped, LTO) |
| RAM idle (RSS) | 57 MB |
| RAM active (100 msgs) | ~20 MB |
| Startup time | < 50 ms |
| Database ops | < 10 ms (session), < 5 ms (message) |
| Embedding engine | embeddinggemma-300M (~300 MB, local GGUF, auto-downloaded) |

#### Memory Search (qmd â€” FTS5 + Vector Embeddings)

Hybrid semantic search: FTS5 BM25 keyword matching + 768-dim vector embeddings combined via Reciprocal Rank Fusion. Embedding model runs locally â€” **no API key, zero cost, works offline**.


Benchmarked with `cargo bench --bench memory` on release builds:

| Operation | Time | Notes |
|-----------|------|-------|
| Store open | 1.81 ms | Cold start (create DB + schema) |
| Index file | 214 Âµs | Insert content + document |
| Hash skip | 19.5 Âµs | Already indexed, unchanged â€” fast path |
| FTS search (10 docs) | 397 Âµs | 2-term BM25 query |
| FTS search (50 docs) | 2.57 ms | Typical user corpus |
| FTS search (100 docs) | 9.22 ms | |
| FTS search (500 docs) | 88.1 ms | Large corpus |
| Vector search (10 docs) | 247 Âµs | 768-dim cosine similarity |
| Vector search (50 docs) | 1.02 ms | 768-dim cosine similarity |
| Vector search (100 docs) | 2.04 ms | 768-dim cosine similarity |
| Hybrid RRF (50 docs) | 3.49 ms | FTS + vector â†’ Reciprocal Rank Fusion |
| Insert embedding | 301 Âµs | Single 768-dim vector |
| Bulk reindex (50 files) | 11.4 ms | From cold, includes store open |
| Deactivate document | 267 Âµs | Prune a single entry |

**Benchmarks** (release build, in-memory SQLite, criterion):

| Operation | Time |
|---|---|
| Index 50 files (first run) | 11.4 ms |
| Per-file index | 214 Âµs |
| Hash skip (unchanged file) | 19.5 Âµs |
| FTS search (10 docs) | 397 Âµs |
| FTS search (50 docs) | 2.57 ms |
| FTS search (100 docs) | 9.2 ms |
| Vector search (10 docs, 768-dim) | 247 Âµs |
| Vector search (50 docs, 768-dim) | 1.02 ms |
| Vector search (100 docs, 768-dim) | 2.04 ms |
| Hybrid RRF (FTS + vector, 50 docs) | 3.49 ms |
| Insert embedding | 301 Âµs |
| Deactivate document | 267 Âµs |

---

## ğŸ› Platform Notes

### Linux

```bash
sudo apt-get install build-essential pkg-config libssl-dev libchafa-dev
```

#### Older CPUs (Sandy Bridge / AVX-only)

The default release binary requires AVX2 (Haswell 2013+). If you have an older CPU with only AVX support (Sandy Bridge/Ivy Bridge, 2011-2012), build from source with:

```bash
RUSTFLAGS="-C target-cpu=native" cargo build --release
```

Pre-built `*-compat` binaries are also available on the [releases page](https://github.com/adolfousier/opencrabs/releases) for AVX-only CPUs. If your CPU lacks AVX entirely (pre-2011), vector embeddings are disabled and search falls back to FTS-only keyword matching.

### macOS

No additional dependencies required.

### Windows

Requires CMake, NASM, and Visual Studio Build Tools for native crypto dependencies:

```bash
# Option 1: Install build tools
# - CMake (add to PATH)
# - NASM (add to PATH)
# - Visual Studio Build Tools ("Desktop development with C++")

# Option 2: Use WSL2 (recommended)
sudo apt-get install build-essential pkg-config libssl-dev
```

See [BUILD_NOTES.md](src/docs/guides/BUILD_NOTES.md) for detailed troubleshooting.

---

## ğŸ”§ Troubleshooting

### Agent Hallucinating Tool Calls

If the agent starts sending tool call approvals that don't render in the UI â€” meaning it believes it executed actions that never actually ran â€” the session context has become corrupted.

**Fix:** Start a new session.

1. Press `/` and type `sessions` (or navigate to the Sessions panel)
2. Press **N** to create a new session
3. Continue your work in the fresh session

This reliably resolves the issue. A fix is coming in a future release.

---

## âš ï¸ Disclaimers

### Development Status

OpenCrabs is under active development. While functional, it may contain bugs or incomplete features.

### Token Cost Responsibility

**You are responsible for monitoring and managing your own API usage and costs.**

- API costs from cloud providers (Anthropic, OpenAI, etc.) are your responsibility
- Set billing alerts with your provider
- Consider local LLMs for cost-free operation
- Use the built-in cost tracker to monitor spending

### Support

Cloud API issues, billing questions, and account problems should be directed to the respective providers. OpenCrabs provides the tool; you manage your API relationships.

---

## ğŸ¤ Contributing

Contributions welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

```bash
# Setup
git clone https://github.com/adolfousier/opencrabs.git
cd opencrabs
cargo build
cargo test
# Make changes, then submit a PR
```

---

## ğŸ“„ License

**MIT License** â€” See [LICENSE.md](LICENSE.md) for details.

---

## ğŸ™ Acknowledgments

- **[Claude Code](https://github.com/anthropics/claude-code)** â€” Inspiration
- **[Crabrace](https://crates.io/crates/crabrace)** â€” Provider registry
- **[Ratatui](https://ratatui.rs/)** â€” Terminal UI framework
- **[Anthropic](https://anthropic.com/)** â€” Claude API

---

## ğŸ“ Support

- **Issues:** [GitHub Issues](https://github.com/adolfousier/opencrabs/issues)
- **Discussions:** [GitHub Discussions](https://github.com/adolfousier/opencrabs/discussions)
- **Docs:** [src/docs/](src/docs/)

---

**Built with Rust ğŸ¦€ by [Adolfo Usier](https://github.com/adolfousier)**
